# Project NLP MVA 23 📚

Welcome to the repoitory of the final project for the Algorithms for Speech and Natural Language Processing class.

## Datasets 📊

This section contains various datasets utilized for training our models.

## Code 👩‍💻

- **Outputs:** Explore our project's code and outputs:
  - [speed_test](#)
  - [content/Project_NLP_MVA_23](#)
  - [pet-master](#)
 

## Final report 
  - [NLPMVA23](#)


## Pattern Exploitation Training (PET) 🧠

### Abstract
Our project is inspired by "It’s not just size that matters" by Schick and Schütze (2020), introducing Pattern Exploitation Training (PET). PET reframes tasks as language modeling problems, using fine-tuned language models to label unlabeled data. This enables classical classifiers with small training datasets and supports few-shot learning. Our project explores PET, replicates its results on various datasets, and compares different masked language models.

### Introduction
Language models like GPT-3 and GPT-4 excel in natural language processing but require substantial computational resources. PET offers an efficient alternative by transforming tasks into language modeling challenges. It uses predefined patterns and verbalizers to convert features into sentences and labels into words. PET facilitates few-shot learning and works well with small training datasets, leveraging easily accessible unlabeled data.

### Project Scope and Findings
Our project replicates Schick and Schütze's study and compares masked language models. While some SuperGLUE tasks showed lower accuracies, sentiment classification tasks performed well. We faced challenges such as labeling errors for specific tasks. Additionally, we created new tasks and explored MLM performance within a few-shot learning paradigm.

### Conclusion
In conclusion, our project provides insights into the effectiveness of Pattern Exploitation Training (PET) for natural language tasks. Despite limitations due to hardware and time constraints, our findings contribute to the discussion on efficient language model training and real-world applications.

## Links 🔗

### Article 📄
- [Read Article 1](https://arxiv.org/pdf/2001.07676.pdf)
- [Read Article 2](https://arxiv.org/pdf/2009.07118.pdf)

### Google Colab 🚀
- [Access Google Colab](https://colab.research.google.com/drive/1zd60dwooww8VV0NCRib-pO9FdeyT01Jv#scrollTo=wxfFVBPrZ5lZ)

### Dataset MNLI 📦
- [Download MNLI Dataset](https://cims.nyu.edu/~sbowman/multinli/multinli_1.0.zip)

### List of all used datasets 📋
- [Explore Datasets](https://paperswithcode.com/paper/it-s-not-just-size-that-matters-small)

### Important YouTube Videos 🎥
- [Watch Video 1](https://www.youtube.com/watch?v=P7Rav5tK3Y0)
- [Watch Video 2](https://youtu.be/01jRE9noSWw)
